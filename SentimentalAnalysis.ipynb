{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5fc183c",
      "metadata": {
        "id": "c5fc183c"
      },
      "source": [
        "## Import functions and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f16fa019",
      "metadata": {
        "id": "f16fa019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "b9b39125-e416-444a-9024-1850991cd02e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'w1_unittest'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bcef5c7d0dbc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetcwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mw1_unittest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#nltk.download('twitter_samples')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'w1_unittest'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# run this cell to import nltk\n",
        "import nltk\n",
        "from os import getcwd\n",
        "import w1_unittest\n",
        "\n",
        "#nltk.download('twitter_samples')\n",
        "#nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "095ac893",
      "metadata": {
        "id": "095ac893"
      },
      "source": [
        "### Imported functions\n",
        "\n",
        "Download the data needed for this.\n",
        "(http://www.nltk.org/howto/twitter.html).\n",
        "\n",
        "* twitter_samples: if you're running this notebook on your local computer, you will need to download it using:\n",
        "```Python\n",
        "nltk.download('twitter_samples')\n",
        "```\n",
        "\n",
        "* stopwords: if you're running this notebook on your local computer, you will need to download it using:\n",
        "```python\n",
        "nltk.download('stopwords')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c0a9c5",
      "metadata": {
        "id": "81c0a9c5"
      },
      "outputs": [],
      "source": [
        "filePath = f\"{getcwd()}/../tmp2/\"\n",
        "nltk.data.path.append(filePath)\n",
        "print(filePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d6334e4",
      "metadata": {
        "id": "1d6334e4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "from utils import process_tweet, build_freqs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2f9522",
      "metadata": {
        "id": "3d2f9522"
      },
      "source": [
        "### Prepare the data\n",
        "* The `twitter_samples` contains subsets of five thousand positive_tweets, five thousand negative_tweets, and the full set of 10,000 tweets.  \n",
        "    * If you used all three datasets, we would introduce duplicates of the positive tweets and negative tweets.  \n",
        "    * You will select just the five thousand positive tweets and five thousand negative tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da241127",
      "metadata": {
        "id": "da241127"
      },
      "outputs": [],
      "source": [
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d153578",
      "metadata": {
        "id": "9d153578"
      },
      "source": [
        "* Train test split: 20% will be in the test set, and 80% in the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603f2da1",
      "metadata": {
        "id": "603f2da1"
      },
      "outputs": [],
      "source": [
        "# split the data into two pieces, one for training and one for testing (validation set)\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4d2d57d",
      "metadata": {
        "id": "c4d2d57d"
      },
      "source": [
        "* Create the numpy array of positive labels and negative labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b579ac",
      "metadata": {
        "id": "56b579ac"
      },
      "outputs": [],
      "source": [
        "# combine positive and negative labels\n",
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addfebbf",
      "metadata": {
        "id": "addfebbf"
      },
      "outputs": [],
      "source": [
        "# Print the shape train and test sets\n",
        "print(\"train_y.shape = \" + str(train_y.shape))\n",
        "print(\"test_y.shape = \" + str(test_y.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef80f927",
      "metadata": {
        "id": "ef80f927"
      },
      "source": [
        "* Create the frequency dictionary using the imported build_freqs function.  \n",
        "    * We highly recommend that you open utils.py and read the build_freqs function to understand what it is doing.\n",
        "    \n",
        "```Python\n",
        "    for y,tweet in zip(ys, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "```\n",
        "* Notice how the outer for loop goes through each tweet, and the inner for loop steps through each word in a tweet.\n",
        "* The 'freqs' dictionary is the frequency dictionary that's being built.\n",
        "* The key is the tuple (word, label), such as (\"happy\",1) or (\"happy\",0).  The value stored for each key is the count of how many times the word \"happy\" was associated with a positive label, or how many times \"happy\" was associated with a negative label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac6ea59d",
      "metadata": {
        "id": "ac6ea59d"
      },
      "outputs": [],
      "source": [
        "# create frequency dictionary\n",
        "freqs = build_freqs(train_x, train_y)\n",
        "\n",
        "# check the output\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d9ba648",
      "metadata": {
        "id": "4d9ba648"
      },
      "source": [
        "#### Expected output\n",
        "```\n",
        "type(freqs) = <class 'dict'>\n",
        "len(freqs) = 11436\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4246f97f",
      "metadata": {
        "id": "4246f97f"
      },
      "source": [
        "### Process tweet\n",
        "The given function 'process_tweet' tokenizes the tweet into individual words, removes stop words and applies stemming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289e4e5f",
      "metadata": {
        "id": "289e4e5f"
      },
      "outputs": [],
      "source": [
        "# test the function below\n",
        "print('This is an example of a positive tweet: \\n', train_x[0])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69dee23e",
      "metadata": {
        "id": "69dee23e"
      },
      "source": [
        "#### Expected output\n",
        "```\n",
        "This is an example of a positive tweet:\n",
        " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
        "\n",
        "This is an example of the processes version:\n",
        " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8b3e5c",
      "metadata": {
        "id": "fe8b3e5c"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html\" > numpy.exp </a> </li>\n",
        "\n",
        "</ul>\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc2889a",
      "metadata": {
        "id": "ccc2889a"
      },
      "outputs": [],
      "source": [
        "# UNQ_C1 GRADED FUNCTION: sigmoid\n",
        "def sigmoid(z):\n",
        "    '''\n",
        "    Input:\n",
        "        z: is the input (can be a scalar or an array)\n",
        "    Output:\n",
        "        h: the sigmoid of z\n",
        "    '''\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # calculate the sigmoid of z\n",
        "    h = None\n",
        "    h=1 / ( 1 + np.exp(-z))\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3bea722",
      "metadata": {
        "id": "c3bea722"
      },
      "outputs": [],
      "source": [
        "# Testing your function\n",
        "if (sigmoid(0) == 0.5):\n",
        "    print('SUCCESS!')\n",
        "else:\n",
        "    print('Oops!')\n",
        "\n",
        "if (sigmoid(4.92) == 0.9927537604041685):\n",
        "    print('CORRECT!')\n",
        "else:\n",
        "    print('Oops again!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a492e1ad",
      "metadata": {
        "id": "a492e1ad"
      },
      "outputs": [],
      "source": [
        "# Test your function\n",
        "w1_unittest.test_sigmoid(sigmoid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d229b2",
      "metadata": {
        "id": "c0d229b2"
      },
      "outputs": [],
      "source": [
        "# verify that when the model predicts close to 1, but the actual label is 0, the loss is a large positive value\n",
        "-1 * (1 - 0) * np.log(1 - 0.9999) # loss is about 9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b041dbc5",
      "metadata": {
        "id": "b041dbc5"
      },
      "outputs": [],
      "source": [
        "# verify that when the model predicts close to 0 but the actual label is 1, the loss is a large positive value\n",
        "-1 * np.log(0.0001) # loss is about 9.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f5b3ab4",
      "metadata": {
        "id": "3f5b3ab4"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>use numpy.dot for matrix multiplication.</li>\n",
        "    <li>To ensure that the fraction -1/m is a decimal value, cast either the numerator or denominator (or both), like `float(1)`, or write `1.` for the float version of 1. </li>\n",
        "</ul>\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ea85e0",
      "metadata": {
        "id": "15ea85e0"
      },
      "outputs": [],
      "source": [
        "# UNQ_C2 GRADED FUNCTION: gradientDescent\n",
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    '''\n",
        "    Input:\n",
        "        x: matrix of features which is (m,n+1)\n",
        "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
        "        theta: weight vector of dimension (n+1,1)\n",
        "        alpha: learning rate\n",
        "        num_iters: number of iterations you want to train your model for\n",
        "    Output:\n",
        "        J: the final cost\n",
        "        theta: your final weight vector\n",
        "    Hint: you might want to print the cost to make sure that it is going down.\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    # get 'm', the number of rows in matrix x\n",
        "    m = None\n",
        "    m = x.shape[0]\n",
        "\n",
        "    for i in range(0, num_iters):\n",
        "\n",
        "        # get z, the dot product of x and theta\n",
        "        z = x.dot(theta)\n",
        "\n",
        "        #sigmoid of z\n",
        "        h = sigmoid(z)\n",
        "\n",
        "        #cost function\n",
        "        J = -1/m*((y.T.dot(np.log(h))) + (1-y).T.dot(np.log(1-h)))\n",
        "\n",
        "        # update the weights theta\n",
        "        theta = theta - (alpha/m) *x.T.dot(h-y)\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    J = float(J)\n",
        "    return J, theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284fc969",
      "metadata": {
        "id": "284fc969"
      },
      "outputs": [],
      "source": [
        "# Check the function\n",
        "# Construct a synthetic test case using numpy PRNG functions\n",
        "np.random.seed(1)\n",
        "# X input is 10 x 3 with ones for the bias terms\n",
        "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
        "# Y Labels are 10 x 1\n",
        "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
        "\n",
        "# Apply gradient descent\n",
        "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
        "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b839d3",
      "metadata": {
        "id": "80b839d3"
      },
      "source": [
        "#### Expected output\n",
        "```\n",
        "The cost after training is 0.67094970.\n",
        "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02a6faec",
      "metadata": {
        "id": "02a6faec"
      },
      "outputs": [],
      "source": [
        "# Test your function\n",
        "w1_unittest.test_gradientDescent(gradientDescent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df17cbc",
      "metadata": {
        "id": "2df17cbc"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>Make sure you handle cases when the (word, label) key is not found in the dictionary. </li>\n",
        "    <li> Search the web for hints about using the 'get' function of a Python dictionary.  Here is an <a href=\"https://www.programiz.com/python-programming/methods/dictionary/get\" > example </a> </li>\n",
        "</ul>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd3b0246",
      "metadata": {
        "id": "cd3b0246"
      },
      "outputs": [],
      "source": [
        "# UNQ_C3 GRADED FUNCTION: extract_features\n",
        "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a list of words for one tweet\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "    Output:\n",
        "        x: a feature vector of dimension (1,3)\n",
        "    '''\n",
        "    # process_tweet tokenizes, stems, and removes stopwords\n",
        "    word_l = process_tweet(tweet)\n",
        "\n",
        "    # 3 elements in the form of a 1 x 3 vector\n",
        "    x = np.zeros((1, 3))\n",
        "\n",
        "    #bias term is set to 1\n",
        "    x[0,0] = 1\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # loop through each word in the list of words\n",
        "    for word in word_l:\n",
        "\n",
        "        j=(word,0)\n",
        "        l=(word,1)\n",
        "\n",
        "        # for -tive label 0\n",
        "        if((word,0) in freqs):\n",
        "            temp=freqs[j]\n",
        "            x[0,2] = x[0,2]+temp\n",
        "\n",
        "        #for the +tive label 1\n",
        "        if((word,1) in freqs):\n",
        "            temp1=freqs[l]\n",
        "            x[0,1] =x[0,1]+temp1\n",
        "\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    assert(x.shape == (1, 3))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54492abe",
      "metadata": {
        "id": "54492abe"
      },
      "outputs": [],
      "source": [
        "# Check your function\n",
        "# test 1\n",
        "# test on training data\n",
        "tmp1 = extract_features(train_x[0], freqs)\n",
        "print(tmp1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879e7a5c",
      "metadata": {
        "id": "879e7a5c"
      },
      "source": [
        "#### Expected output\n",
        "```\n",
        "[[1.000e+00 3.133e+03 6.100e+01]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3871b163",
      "metadata": {
        "id": "3871b163"
      },
      "outputs": [],
      "source": [
        "# test 2:\n",
        "# check for when the words are not in the freqs dictionary\n",
        "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
        "print(tmp2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dca94e31",
      "metadata": {
        "id": "dca94e31"
      },
      "source": [
        "#### Expected output\n",
        "```\n",
        "[[1. 0. 0.]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "770e4ba5",
      "metadata": {
        "id": "770e4ba5"
      },
      "outputs": [],
      "source": [
        "# Test your function\n",
        "w1_unittest.test_extract_features(extract_features, freqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec2b544",
      "metadata": {
        "id": "6ec2b544",
        "outputId": "33e7fcf4-ba81-493f-b88f-485a289ed558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The cost after training is 0.22521397.\n",
            "The resulting vector of weights is [6e-08, 0.0005382, -0.0005583]\n"
          ]
        }
      ],
      "source": [
        "# collect the features 'x' and stack them into a matrix 'X'\n",
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "\n",
        "# training labels corresponding to X\n",
        "Y = train_y\n",
        "\n",
        "# Apply gradient descent\n",
        "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7249769f",
      "metadata": {
        "id": "7249769f"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "```\n",
        "The cost after training is 0.22522315.\n",
        "The resulting vector of weights is [6e-08, 0.00053818, -0.0005583]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1123f09",
      "metadata": {
        "id": "b1123f09"
      },
      "outputs": [],
      "source": [
        "# UNQ_C4 GRADED FUNCTION: predict_tweet\n",
        "def predict_tweet(tweet, freqs, theta):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "        theta: (3,1) vector of weights\n",
        "    Output:\n",
        "        y_pred: the probability of a tweet being positive or negative\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # extract the features of the tweet and store it into x\n",
        "    x = extract_features(tweet,freqs)\n",
        "\n",
        "    # make the prediction using x and theta\n",
        "    y_pred = sigmoid(np.dot(x,theta))\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8008d7af",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "8008d7af",
        "outputId": "69bb04d8-5a41-497d-91a9-3fb390f3825f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am happy -> 0.519275\n",
            "I am bad -> 0.494347\n",
            "this movie should have been great. -> 0.515980\n",
            "great -> 0.516065\n",
            "great great -> 0.532097\n",
            "great great great -> 0.548063\n",
            "great great great great -> 0.563930\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function\n",
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "085506e8",
      "metadata": {
        "id": "085506e8"
      },
      "source": [
        "**Expected Output**:\n",
        "```\n",
        "I am happy -> 0.519275\n",
        "I am bad -> 0.494347\n",
        "this movie should have been great. -> 0.515979\n",
        "great -> 0.516065\n",
        "great great -> 0.532096\n",
        "great great great -> 0.548062\n",
        "great great great great -> 0.563929\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "369da102",
      "metadata": {
        "id": "369da102"
      },
      "outputs": [],
      "source": [
        "# Feel free to check the sentiment of your own tweet below\n",
        "my_tweet = 'I am learning :)'\n",
        "predict_tweet(my_tweet, freqs, theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1374ab5",
      "metadata": {
        "id": "d1374ab5"
      },
      "outputs": [],
      "source": [
        "# Test your function\n",
        "w1_unittest.test_predict_tweet(predict_tweet, freqs, theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "934b1dec",
      "metadata": {
        "id": "934b1dec"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>Use np.asarray() to convert a list to a numpy array</li>\n",
        "    <li>Use numpy.squeeze() to make an (m,1) dimensional array into an (m,) array </li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e299bc43",
      "metadata": {
        "id": "e299bc43"
      },
      "outputs": [],
      "source": [
        "# UNQ_C5 GRADED FUNCTION: test_logistic_regression\n",
        "def test_logistic_regression(test_x, test_y, freqs, theta, predict_tweet=predict_tweet):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: a list of tweets\n",
        "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
        "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
        "        theta: weight vector of dimension (3, 1)\n",
        "    Output:\n",
        "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # the list for storing predictions\n",
        "    y_hat = []\n",
        "\n",
        "    for tweet in test_x:\n",
        "        # get the label prediction for the tweet\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "\n",
        "        if y_pred > 0.5:\n",
        "            # append 1.0 to the list\n",
        "            y_hat.append(1.0)\n",
        "        else:\n",
        "            # append 0 to the list\n",
        "            y_hat.append(0.0)\n",
        "\n",
        "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
        "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
        "\n",
        "    j=0\n",
        "\n",
        "    y_hat_data=np.array(y_hat)\n",
        "\n",
        "    test_y_data=test_y.flatten()\n",
        "\n",
        "\n",
        "    for i in range(0,len(y_hat_data)):\n",
        "\n",
        "        if y_hat_data[i]==test_y_data[i]:\n",
        "\n",
        "            j+=1\n",
        "\n",
        "    accuracy = j/len(test_y_data)\n",
        "\n",
        "    accuracy=np.float(accuracy)\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2414350",
      "metadata": {
        "id": "e2414350",
        "outputId": "4f60d1e8-2488-4ed8-cb32-4d3e9fc0c968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic regression model's accuracy = 0.9950\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-121-366b5fa2b673>:47: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  accuracy=np.float(accuracy)\n"
          ]
        }
      ],
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e204ab3",
      "metadata": {
        "id": "0e204ab3"
      },
      "source": [
        "#### Expected Output:\n",
        "```0.9950```  \n",
        "Pretty good!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a1141e8",
      "metadata": {
        "id": "3a1141e8",
        "outputId": "87523f53-edec-45d5-e0a0-e48dde9d598f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m All tests passed\n"
          ]
        }
      ],
      "source": [
        "# Test your function\n",
        "w1_unittest.unittest_test_logistic_regression(test_logistic_regression, freqs, theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa93a74",
      "metadata": {
        "id": "baa93a74",
        "outputId": "0056e61c-ab6d-4afb-dc1d-cbd62eb14699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Predicted Tweet\n",
            "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
            "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
            "1\t0.48943045\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots\n",
            "http://t.co/UGQzOx0huu\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48419007\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48419007\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48419007\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: off to the park to get some sunlight : )\n",
            "THE PROCESSED TWEET IS: ['park', 'get', 'sunlight']\n",
            "1\t0.49636422\tb'park get sunlight'\n",
            "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
            "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
            "1\t0.48250541\tb'uff itna miss karhi thi ap :p'\n",
            "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
            "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
            "0\t0.50988312\tb'u prob fun david'\n",
            "THE TWEET IS: pats jay : (\n",
            "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
            "0\t0.50040366\tb'pat jay'\n",
            "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
            "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
            "0\t0.50000002\tb'belov grandmoth'\n",
            "THE TWEET IS: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
            "THE PROCESSED TWEET IS: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
            "0\t0.50648702\tb'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'\n"
          ]
        }
      ],
      "source": [
        "# Some error analysis done for you\n",
        "print('Label Predicted Tweet')\n",
        "for x,y in zip(test_x,test_y):\n",
        "    y_hat = predict_tweet(x, freqs, theta)\n",
        "\n",
        "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
        "        print('THE TWEET IS:', x)\n",
        "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
        "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a22ac122",
      "metadata": {
        "id": "a22ac122"
      },
      "source": [
        "Later in this specialization, we will see how we can use deeplearning to improve the prediction performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d7c8f6",
      "metadata": {
        "id": "93d7c8f6",
        "outputId": "c633bf31-976e-423f-8678-f9ab688ce202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
            "[[0.48125433]]\n",
            "Negative sentiment\n"
          ]
        }
      ],
      "source": [
        "# Feel free to change the tweet below\n",
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
        "print(process_tweet(my_tweet))\n",
        "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else:\n",
        "    print('Negative sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce270e6",
      "metadata": {
        "id": "6ce270e6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "envpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "e9dda0523ffaa6e181c594552fc1aea103e69dec7eaf6c8fa6df98b304b552ea"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}